{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Load data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load environment variables\n",
    "# ---------------------------\n",
    "load_dotenv(dotenv_path='/home/jovyan/work/Medicina/DuETT - DP/DialysisDuETT/.env')\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Define target keys and retrieve pickle file paths from .env\n",
    "# ---------------------------\n",
    "target_keys = ['ANALITICAS', 'ANEMIA', 'CATETER', 'CINETICA', \n",
    "               'EXTEMP', 'INGRESOS', 'MOM', 'PACIENTES', 'PERITONITIS']\n",
    "\n",
    "# Retrieve paths from the environment variables\n",
    "target_paths = {}\n",
    "for key in target_keys:\n",
    "    path = os.getenv(key)\n",
    "    if path is None:\n",
    "        print(f\"Warning: Environment variable {key} not found in the .env file.\")\n",
    "    else:\n",
    "        target_paths[key] = path\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Load the pickle files into DataFrames\n",
    "# ---------------------------\n",
    "levantedp = {}  # Dictionary to hold the loaded DataFrames\n",
    "\n",
    "for key, pkl_path in target_paths.items():\n",
    "    if os.path.exists(pkl_path):\n",
    "        try:\n",
    "            df = pd.read_pickle(pkl_path)\n",
    "            levantedp[key] = df\n",
    "            print(f\"Loaded DataFrame for '{key}' from '{pkl_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pickle file for '{key}' from '{pkl_path}': {e}\")\n",
    "    else:\n",
    "        print(f\"Pickle file for '{key}' not found at '{pkl_path}'.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Unpack DataFrames into global variables\n",
    "# ---------------------------\n",
    "for key, df in levantedp.items():\n",
    "    globals()[key] = df\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: General adjustments\n",
    "# ---------------------------\n",
    "\n",
    "# Ensure the FECHA column is in datetime format\n",
    "ANALITICAS['FECHA'] = pd.to_datetime(ANALITICAS['FECHA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas Display Options\n",
    "pd.set_option('display.max_rows', None)  # Show all rows (if needed)\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  # Adjust the output width\n",
    "pd.set_option('display.max_colwidth', None)  # Prevent column content truncation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Missing values by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to report missing values\n",
    "def missing_values_report(df, df_name):\n",
    "    \"\"\"\n",
    "    Prints a report of the absolute number and percentage of missing values (NaN and empty)\n",
    "    for each column in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Replace empty strings (or strings with only whitespace) with NaN\n",
    "    df_clean = df.replace(r'^\\s*$', pd.NA, regex=True)\n",
    "    \n",
    "    total_rows = len(df_clean)\n",
    "    # Calculate missing values count and percentage for each column\n",
    "    missing_count = df_clean.isnull().sum()\n",
    "    missing_percentage = (missing_count / total_rows * 100).round(2)\n",
    "    \n",
    "    report_df = pd.DataFrame({\n",
    "        'Missing Values': missing_count,\n",
    "        'Percentage (%)': missing_percentage\n",
    "    })\n",
    "    \n",
    "    print(f\"Missing Values Report for '{df_name}' (Total Rows: {total_rows}):\")\n",
    "    display(HTML(report_df.to_html()))    \n",
    "    print(\"\\n\")\n",
    "\n",
    "# Check and print the missing values report for ANALITICAS\n",
    "if \"ANALITICAS\" in levantedp:\n",
    "    missing_values_report(levantedp[\"ANALITICAS\"], \"ANALITICAS\")\n",
    "else:\n",
    "    print(\"DataFrame for 'ANALITICAS' not found in levantedp.\")\n",
    "\n",
    "# Check and print the missing values report for PACIENTES\n",
    "if \"PACIENTES\" in levantedp:\n",
    "    missing_values_report(levantedp[\"PACIENTES\"], \"PACIENTES\")\n",
    "else:\n",
    "    print(\"DataFrame for 'PACIENTES' not found in levantedp.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Average distance (days) between meassurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by patient and date\n",
    "ANALITICAS.sort_values(['REGISTRO', 'FECHA'], inplace=True)\n",
    "\n",
    "# Calculate the difference in days between consecutive measurements for each patient\n",
    "ANALITICAS['diff_days'] = ANALITICAS.groupby('REGISTRO')['FECHA'].diff().dt.days\n",
    "\n",
    "# Merge with PACIENTES DataFrame to get the CENTRO information\n",
    "ANALITICAS_merged = ANALITICAS.merge(PACIENTES[['REGISTRO', 'CENTRO']], on='REGISTRO', how='left')\n",
    "\n",
    "# 1. Calculate the average interval for every patient (ignoring NaN values)\n",
    "patient_avg = ANALITICAS_merged.groupby('REGISTRO')['diff_days'].mean()\n",
    "\n",
    "# 2. Calculate the general average interval (across all valid differences)\n",
    "general_avg = ANALITICAS_merged['diff_days'].mean()\n",
    "\n",
    "# 3. Calculate the average interval for every CENTRO\n",
    "centro_avg = ANALITICAS_merged.groupby('CENTRO')['diff_days'].mean()\n",
    "\n",
    "# 4. Calculate the number of unique patients per CENTRO\n",
    "unique_patients_per_centro = ANALITICAS_merged.groupby('CENTRO')['REGISTRO'].nunique()\n",
    "\n",
    "# 5. Calculate the total number of measurements per CENTRO\n",
    "measurements_per_centro = ANALITICAS_merged.groupby('CENTRO')['REGISTRO'].count()\n",
    "\n",
    "# Combine results into a DataFrame for better readability\n",
    "centro_results = pd.DataFrame({\n",
    "    'Average Interval (days)': centro_avg,\n",
    "    'Unique Patients': unique_patients_per_centro,\n",
    "    'Total Measurements': measurements_per_centro\n",
    "}).reset_index()\n",
    "\n",
    "# Output the results\n",
    "print(\"General average (days):\", general_avg)\n",
    "print(\"\\nAverage for every CENTRO (days), Unique Patients, and Total Measurements:\")\n",
    "print(centro_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
